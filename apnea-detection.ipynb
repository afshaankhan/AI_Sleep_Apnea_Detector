{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6420017,"sourceType":"datasetVersion","datasetId":3703360}],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Overview\nThis project aims to develop a deep learning model to detect apnea using physiological signals. Apnea, a potentially serious sleep disorder, involves periods during which breathing stops or becomes shallow during sleep. Early detection is crucial for effective management and treatment.\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-02T09:49:37.175664Z","iopub.execute_input":"2024-05-02T09:49:37.176015Z","iopub.status.idle":"2024-05-02T09:49:52.982265Z","shell.execute_reply.started":"2024-05-02T09:49:37.175985Z","shell.execute_reply":"2024-05-02T09:49:52.981456Z"}}},{"cell_type":"code","source":"# Core libraries\nimport numpy as np\nimport pandas as pd\n\n# Data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Machine Learning and Data Processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.manifold import TSNE\n\n# Deep Learning\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Data Loading\nimport wfdb\n\n# IPython utilities for better display\nfrom IPython.display import display\n","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Functions to load and process the data\n\ndef process_patient_data(patient_id, data_dir):\n    file_name = f'/{patient_id}'\n\n    # Load patient data\n    record = wfdb.rdheader(data_dir + file_name)\n    signals, fields = wfdb.rdsamp(data_dir + file_name)\n    sleep_stage_annotations = wfdb.rdann(data_dir + file_name, 'st')\n\n    # Initial definitions\n    signal_names = fields['sig_name']\n    signals_to_keep = ['ECG', 'BP', 'EEG']\n    sampling_rate = 250\n    window_length_samples = 30 * sampling_rate\n\n    # Calculate the start index and the starting time\n    start_index = sleep_stage_annotations.sample[0]\n    time_start = start_index / sampling_rate\n    adjusted_start_index = int(time_start * sampling_rate)\n\n    # Filter and build the dictionary of selected signals\n    filtered_signals_dict = {\n        name: signals[:, i] if sleep_stage_annotations.sample[0] == 1 else signals[adjusted_start_index:, i]\n        for i, name in enumerate(signal_names) if any(sig in name for sig in signals_to_keep)\n    }\n\n    # Split the signals into windows of 7500 samples\n    windowed_signals_dict = {\n        name: signal[:(len(signal) // window_length_samples) * window_length_samples].reshape(-1, window_length_samples)\n        for name, signal in filtered_signals_dict.items()\n    }\n\n    # Extract labels for apneas\n    apnea_values = ['H', 'HA', 'OA', 'X', 'CA', 'CAA']\n    apnea_labels = [1 if any(marker in note for marker in apnea_values) else 0 for note in sleep_stage_annotations.aux_note]\n\n    # Build the final dictionary with the signals and associated labels\n    windows_with_labels = {\n        f\"{patient_id}_Window_{index}\": {**{name: signals[index] for name, signals in windowed_signals_dict.items()}, 'Label': apnea_labels[index]}\n        for index in range(min(len(next(iter(windowed_signals_dict.values()))), len(apnea_labels)))\n    }\n\n    return windows_with_labels\n\n ##################################################################################################################\n\ndef prepare_data(windows_with_labels):\n    X_list = []\n    for window in windows_with_labels.values():\n        # Retrieve all values except the last one (which is the label)\n        signals = list(window.values())[:-1]\n        # Concatenate the signal arrays along a new axis to create a single numpy array for each window\n        concatenated_signals = np.concatenate([signal[np.newaxis, :] for signal in signals], axis=0)\n        X_list.append(concatenated_signals)\n\n    # Convert the list of numpy arrays into a single numpy array\n    X = np.array(X_list)\n\n    # 'X' now has shape (number_of_windows, number_of_signals, samples_per_window)\n    # Transpose 'X' to get the correct shape for LSTM model input: (number_of_windows, samples_per_window, number_of_signals)\n    X = np.transpose(X, (0, 2, 1))\n\n    # Extract labels from the dictionary 'windows_with_labels'\n    y = np.array([window['Label'] for window in windows_with_labels.values()])\n\n    return X, y\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T09:50:18.913707Z","iopub.execute_input":"2024-05-02T09:50:18.914898Z","iopub.status.idle":"2024-05-02T09:50:18.929956Z","shell.execute_reply.started":"2024-05-02T09:50:18.914859Z","shell.execute_reply":"2024-05-02T09:50:18.929031Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Data directory and list of patients\ndata_dir = '/kaggle/input/mit-bih-psg-database-try-2/mit-bih-polysomnographic-database-1.0.0'\npatient_ids = ['slp04', 'slp66', 'slp16']\n\n\n# Global dictionary to hold data from all patients\nall_windows = {}\n\n# Process data for each patient and accumulate the results\nfor patient_id in patient_ids:\n    patient_data = process_patient_data(patient_id, data_dir)\n    all_windows.update(patient_data)  # Add data from each patient to the global dictionary\n\n# Print a summary of the results\nprint(f'Total windows processed from all patients: {len(all_windows)}')\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T09:55:50.720569Z","iopub.execute_input":"2024-05-02T09:55:50.721487Z","iopub.status.idle":"2024-05-02T09:55:52.600733Z","shell.execute_reply.started":"2024-05-02T09:55:50.721452Z","shell.execute_reply":"2024-05-02T09:55:52.599714Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare the data for the LSTM model\nX, y = prepare_data(all_windows)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-05-02T09:55:55.283252Z","iopub.execute_input":"2024-05-02T09:55:55.283895Z","iopub.status.idle":"2024-05-02T09:55:55.772255Z","shell.execute_reply.started":"2024-05-02T09:55:55.283863Z","shell.execute_reply":"2024-05-02T09:55:55.771465Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training model\n\n# Define the model with a compact structure including Dropout\nmodel = Sequential([\n    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n    Dropout(0.2),  # Adds Dropout after the first LSTM\n    LSTM(32, return_sequences=False),\n    Dropout(0.2),  # Adds Dropout after the second LSTM\n    Dense(32, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\n# Uncomment the following line if learning rate reduction is needed\n# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1)\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()\n\n# Configuration for EarlyStopping callback\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # Monitor validation loss\n    patience=20,  # Number of epochs with no improvement after which training will be stopped\n    verbose=1,  # Show messages\n    restore_best_weights=True  # Restore model weights from the best epoch\n)\n\n# Training the model with EarlyStopping\nhistory = model.fit(\n    X_train, y_train,\n    epochs=100,\n    batch_size=32,\n    validation_split=0.2,\n    callbacks=[early_stopping]  # Add the callback to the list of callbacks\n)\n\n# Model evaluation\nval_loss, val_acc = model.evaluate(X_test, y_test, verbose=2)\nprint(f\"Model evaluation - Loss: {val_loss}, Accuracy: {val_acc}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T09:56:00.134791Z","iopub.execute_input":"2024-05-02T09:56:00.135143Z","iopub.status.idle":"2024-05-02T10:18:04.884411Z","shell.execute_reply.started":"2024-05-02T09:56:00.135113Z","shell.execute_reply":"2024-05-02T10:18:04.883412Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extracting accuracy and loss data from the history object\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(acc) + 1)\n\n# Creating the plot for accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs, acc, 'bo-', label='Training Acc')\nplt.plot(epochs, val_acc, 'r^-', label='Validation Acc')\nplt.title('Training and Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\n# Creating the plot for loss\nplt.subplot(1, 2, 2)\nplt.plot(epochs, loss, 'bo-', label='Training Loss')\nplt.plot(epochs, val_loss, 'r^-', label='Validation Loss')\nplt.title('Training and Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-02T10:19:16.878569Z","iopub.execute_input":"2024-05-02T10:19:16.879359Z","iopub.status.idle":"2024-05-02T10:19:17.544552Z","shell.execute_reply.started":"2024-05-02T10:19:16.87932Z","shell.execute_reply":"2024-05-02T10:19:17.543704Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predicting the outputs using the model on the test data\ny_pred = model.predict(X_test)\n# Rounding the predictions to the nearest integer\ny_pred = np.round(y_pred).astype(int)\n# Printing the classification report comparing actual and predicted values\nprint(classification_report(y_test, y_pred, target_names=['No Apnea', 'Apnea']))\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T10:19:56.467552Z","iopub.execute_input":"2024-05-02T10:19:56.467941Z","iopub.status.idle":"2024-05-02T10:19:58.717762Z","shell.execute_reply.started":"2024-05-02T10:19:56.467901Z","shell.execute_reply":"2024-05-02T10:19:58.716834Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creating a confusion matrix from the test labels and predicted labels\ncm = confusion_matrix(y_test, y_pred)\n\n# Setting up the plot for the confusion matrix\nplt.figure(figsize=(8, 6))\n# Visualizing the confusion matrix as a heatmap\nsns.heatmap(cm, annot=True, fmt='g', cmap='Blues', cbar=False)\n# Labeling the x-axis as 'Predicted'\nplt.xlabel('Predicted')\n# Labeling the y-axis as 'True'\nplt.ylabel('True')\n# Setting the title of the plot as 'Confusion matrix'\nplt.title('Confusion matrix')\n# Displaying the plot\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-02T10:20:02.254827Z","iopub.execute_input":"2024-05-02T10:20:02.255209Z","iopub.status.idle":"2024-05-02T10:20:02.453143Z","shell.execute_reply.started":"2024-05-02T10:20:02.255183Z","shell.execute_reply":"2024-05-02T10:20:02.452214Z"},"trusted":true},"outputs":[],"execution_count":null}]}